{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GBC Training score:  0.814814814815\n",
      "GBC Testing score:  0.830065359477\n",
      "GridSearchCV(cv=None, error_score='raise',\n",
      "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
      "              learning_rate=0.1, loss='deviance', max_depth=3,\n",
      "              max_features=None, max_leaf_nodes=None,\n",
      "              min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "              min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "              n_estimators=100, presort='auto', random_state=None,\n",
      "              subsample=1.0, verbose=0, warm_start=False),\n",
      "       fit_params={}, iid=True, n_jobs=-1,\n",
      "       param_grid=[{'max_depth': [1, 2, 3, 4, 5], 'n_estimators': [10, 60, 110, 160, 210, 260, 310, 360, 410, 460], 'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import pandas_profiling\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from  xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "df_train = pd.read_csv('train.csv')\n",
    "\n",
    "#############################################   Few Outlier Conditions ###############################\n",
    "\n",
    "df_train = df_train[df_train['ApplicantIncome']<=60000]\n",
    "\n",
    "######################################################################################################\n",
    "\n",
    "\n",
    "df_test = pd.read_csv('test.csv')\n",
    "y = df_train['Loan_Status']\n",
    "\n",
    "df_test_loanID = df_test['Loan_ID'].to_frame()\n",
    "\n",
    "df_train.drop('Loan_ID', 1, inplace = True)\n",
    "df_test.drop('Loan_ID', 1, inplace = True)\n",
    "\n",
    "df_train['Loan_Status'] = [1 if val == 'Y' \n",
    "                           else 0\n",
    "                     for val in df_train['Loan_Status']]\n",
    "\n",
    "\n",
    "def data_explore(df_train):\n",
    "    ser_gender = df_train['Gender'].value_counts()\n",
    "    df_train['Gender'].fillna(ser_gender[ser_gender == max(ser_gender)].index[0], inplace = True)\n",
    "\n",
    "\n",
    "    ser_married = df_train['Married'].value_counts()\n",
    "    df_train['Married'].fillna(ser_married[ser_married == max(ser_married)].index[0], inplace = True)\n",
    "\n",
    "    ser_dependents = df_train['Dependents'].value_counts()\n",
    "    df_train['Dependents'].fillna(ser_dependents[ser_dependents == max(ser_dependents)].index[0], inplace = True)\n",
    "\n",
    "\n",
    "    ser_self_employed = df_train['Self_Employed'].value_counts()\n",
    "    df_train['Self_Employed'].fillna(ser_self_employed[ser_self_employed == max(ser_self_employed)].index[0], inplace = True)\n",
    "\n",
    "    ser_loanamount = (df_train['LoanAmount'].median() + df_train['LoanAmount'].mean())/2\n",
    "    df_train['LoanAmount'].fillna(ser_loanamount, inplace = True)\n",
    "\n",
    "    ser_loanterm_amount = (df_train['Loan_Amount_Term'].median() + df_train['Loan_Amount_Term'].mean())/2\n",
    "    df_train['Loan_Amount_Term'].fillna(ser_loanterm_amount, inplace = True)\n",
    "\n",
    "    ser_credit_history = df_train['Credit_History'].mean()\n",
    "    df_train['Credit_History'].fillna(ser_credit_history, inplace = True)\n",
    "\n",
    "    for column in df_train.columns:\n",
    "        text_val_dict = {}\n",
    "        if df_train[column].dtypes not in ('int64', 'float64'):\n",
    "            column_contents = list(df_train[column].unique().astype(str))\n",
    "            column_contents.sort()\n",
    "            i = 0\n",
    "            for content in column_contents:\n",
    "                text_val_dict[content] = i\n",
    "                i+=1\n",
    "            df_train[column] = df_train[column].map(text_val_dict)\n",
    "    return df_train\n",
    "\n",
    "df_train_final_1 = data_explore(df_train)\n",
    "df_train_final = df_train_final_1.drop('Loan_Status', 1)\n",
    "df_test_final = data_explore(df_test)\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train_final, y, random_state = 0)\n",
    "\n",
    "\n",
    "# # Random Forests Classifier\n",
    "# model_RFC = RandomForestClassifier(n_estimators = 100,n_jobs = -1,  \n",
    "#                                    min_samples_leaf = 10, random_state = 1).fit(X_train, y_train)\n",
    "# print('RFC Train score: ', model_RFC.score(X_train, y_train))\n",
    "# print('RFC Test score: ', model_RFC.score(X_test, y_test))\n",
    "# # print('\\n')\n",
    "\n",
    "# # Logistic Regression Classifier\n",
    "# model_log = LogisticRegression().fit(X_train, y_train)\n",
    "# print('Train score: ', model_log.score(X_train, y_train))\n",
    "# print('Test score: ', model_log.score(X_test, y_test))\n",
    "# # print('\\n')\n",
    "min_samples = list(range(1,50))\n",
    "n_estimator = list(range(10, 500, 50))\n",
    "# XGB Classifier\n",
    "param_list = [ {'max_depth' : [1, 2, 3, 4, 5],\n",
    "               'n_estimators' : n_estimator, 'learning_rate': [0.001, 0.01, 0.1, 1, 10, 100], }]\n",
    "# XGBClassifier().get_params().keys()\n",
    "\n",
    "clf = GridSearchCV(estimator = GradientBoostingClassifier(), param_grid = param_list, n_jobs = -1)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# model_xgb = XGBClassifier(param_grid = param_list).fit(X_train, y_train)\n",
    "print('GBC Training score: ', clf.score(X_train, y_train))\n",
    "print('GBC Testing score: ', clf.score(X_test, y_test))\n",
    "print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best gamma: 1\n",
      "Best Max depth: 3\n",
      "Best estimator size: 410\n",
      "Best learning rate: 0.01\n",
      "Best score for data1: 0.803921568627451\n",
      "Training score:  0.806100217865\n",
      "Testing score:  0.843137254902\n"
     ]
    }
   ],
   "source": [
    "print('Best gamma:', clf.best_estimator_.gamma)\n",
    "print('Best Max depth:',clf.best_estimator_.max_depth) \n",
    "print('Best estimator size:',clf.best_estimator_.n_estimators)\n",
    "print('Best learning rate:',clf.best_estimator_.learning_rate)\n",
    "print('Best score for data1:', clf.best_score_)\n",
    "print('Training score: ', clf.score(X_train, y_train))\n",
    "print('Testing score: ', clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
